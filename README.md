# Мультимодальный метод глубокого обучения:

Эта проблема относится к категории классификации с несколькими метками и поиска продукта. Иногда для этой задачи помогают текстовые данные о товаре (название и описание товара), а иногда помогают изображения товара. Следовательно, нам нужна модель глубокого обучения, которая учитывает как изображение продукта, так и текст. Вот почему требуется мультимодальный метод глубокого обучения, с его помощью мы можем генерировать такие вложения, которые включают как текстовое, так и графическое представление продукта, которые могут помочь в дальнейших последующих задачах по классификации и поиску продукта.

# Статья HUSE:

Многие идеи, реализованные здесь, взяты из этой статьи. Я упомянул в блокноте, где я взял ссылку из этой статьи. Вы можете пойти и прочитать этот раздел для лучшего понимания.

# Обзор статьи

﻿HUSE: Hierarchical Universal Semantic Embeddings (https://arxiv.org/pdf/1911.05978.pdf) В этой статье предлагается новый метод HUSE для изучения кросс-модального представления с семантической информацией. HUSE изучает общее скрытое пространство, в котором расстояние между любыми двумя универсальными вложениями аналогично расстоянию между их соответствующими вложениями классов в пространстве семантических вложений. HUSE также использует цель классификации с общим классификационным слоем, чтобы убедиться, что встраивание изображения и текста находится в одном и том же общем скрытом пространстве.
 
# ЧАСТЬ 1: СОЗДАНИЕ ВНЕДРЕНИЯ ТЕКСТА И ИЗОБРАЖЕНИЯ.

HUSE, будучи мультимодальной моделью, принимает два входа: изображение и текст. Изображение передается в предварительно обученную модель изображения VGG16, которая создает вложение для отдельных изображений и обучает небольшую модель, которая используется для получения представления текста.

# ЧАСТЬ 2: РЕАЛИЗАЦИЯ МОДЕЛИ ДЛЯ СОЗДАНИЯ ОКОНЧАТЕЛЬНЫХ ВЛОЖЕНИЙ:

Выходные данные VGG16 передаются в Image Tower параллельно с выходными данными текстовой модели, которые передаются в Text Tower. Нормализованный выходной сигнал L2 от обеих башен далее передается на общий полносвязный уровень. Выходные данные общего полносвязного слоя в дальнейшем используются для расчета различных потерь. ﻿

# ЧАСТЬ 3: ВКЛЮЧЕНИЕ ТРЕХ УТРАТ В АРХИТЕКТУРУ:

Документ включает три потери: сходство на уровне класса, семантическое сходство, перекрестный модальный разрыв. Все три потери подробно описаны в статье.

# Полученные результаты:

Мы смогли достичь точности 98,21% на тестовом наборе данных, тогда как мы получили точность 98,69% на наборе данных поезда.
